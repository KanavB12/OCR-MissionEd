# -*- coding: utf-8 -*-
"""Segmentation&Testing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LHJBI46b1zqQQl3XpRrpy-kkLsJCE4ra

# Import Libraries
"""

import matplotlib.pyplot as plt
import cv2
import numpy as np
from skimage.morphology import skeletonize, thin
np.set_printoptions(threshold=np.inf)

"""## Word Segmentation"""

image = cv2.imread(r'Easy.jpeg')
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

img = cv2.bitwise_not(gray)

ret,thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)

plt.figure(figsize=  (12, 32))
plt.imshow(thresh, cmap='gray')
plt.show()

plt.figure(figsize=  (12, 32))
plt.imshow(image, cmap='gray')
plt.show()

kernel = np.ones((3,3),np.uint8)
dilation = cv2.dilate(np.float32(thresh), kernel, iterations = 5)

plt.figure(figsize = (12, 32))
plt.imshow(dilation, cmap='gray')
plt.show()

#test = skeleton.copy()
test1 = dilation.copy()

#thresh_image = thresh_image.astype(np.uint8)
contours, hierarchy = cv2.findContours(np.uint8(test1), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

print("Number of Contours = " + str(len(contours)))

original = image.copy()
cont = cv2.drawContours(np.uint8(original), contours, -1, (100, 0, 0), 3)
plt.figure(figsize = (12, 32))
plt.imshow(cont)

max = 0
for contour in contours:
  area = cv2.contourArea(contour)
  if area > max:
    max = area

limit = max*3//100
original = image.copy()
for contour in contours:
  area = cv2.contourArea(contour)
  if area > limit :
    x,y,w,h = cv2.boundingRect(contour)
    rect = cv2.rectangle(original,(x,y),(x+w,y+h),(100,0,0), 2)

plt.figure(figsize = (12, 32))
plt.imshow(rect)

max = 0
for contour in contours:
  area = cv2.contourArea(contour)
  if area > max:
    max = area

limit = max*3//100

boundingBoxes = []
for c in contours:
  area = cv2.contourArea(c)
  if area > limit:
    boundingBoxes.append(cv2.boundingRect(c))

len(boundingBoxes)

avg_h = 0
for i in range(0, len(boundingBoxes)):
  avg_h += boundingBoxes[i][3]

avg_h = avg_h//len(boundingBoxes)
avg_h += avg_h*5//100

tolerance_factor = avg_h
sorted_cnt = sorted(boundingBoxes, key = lambda x: ( ((x[1] + tolerance_factor) // (2*tolerance_factor)) *2*tolerance_factor) * image.shape[1] + x[0])

char_list = "!\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"


# string.ascii_letters + string.digits (Chars & Digits)
# or 
# "!\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"

print(char_list, len(char_list))

def encode_to_labels(txt):
    # encoding each output word into digits
    dig_lst = []
    for index, chara in enumerate(txt):
        dig_lst.append(char_list.index(chara))
        
    return dig_lst

def process_image(img):
    """
    Converts image to shape (32, 128, 1) & normalize
    """
    w, h = img.shape
    
#     _, img = cv2.threshold(img, 
#                            128, 
#                            255, 
#                            cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    
    # Aspect Ratio Calculation
    new_w = 32
    new_h = int(h * (new_w / w))
    img = cv2.resize(img, (new_h, new_w), interpolation = cv2.INTER_AREA)
    w, h = img.shape
    
    img = img.astype('float32')
    
    # Converts each to (32, 128, 1)
    if w < 32:
        add_zeros = np.full((32-w, h), 255)
        img = np.concatenate((img, add_zeros))
        w, h = img.shape
    
    if h < 128:
        add_zeros = np.full((w, 128-h), 255)
        img = np.concatenate((img, add_zeros), axis=1)
        w, h = img.shape
        
    if h > 128 or w > 32:
        dim = (128,32)
        img = cv2.resize(img, dim)
    
    img = cv2.subtract(255, img)
    
    img = np.expand_dims(img, axis=2)
    
    # Normalize 
    img = img / 255
    
    return img

Images = []

for i in range(0, len(sorted_cnt)):
  x = sorted_cnt[i][0]
  y = sorted_cnt[i][1]
  w = sorted_cnt[i][2]
  h = sorted_cnt[i][3]

  orig = image[y:y+h, x:x+w]

  # Converting to Grayscale
  gray = cv2.cvtColor(orig, cv2.COLOR_BGR2GRAY)

  kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
  #removing_noise = cv2.fastNlMeansDenoising(gray, h=40, templateWindowSize=5,searchWindowSize=21)
  #im = cv2.filter2D(removing_noise, -1, kernel)

  # Converting to a Binary Image
  ret,thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)

  # Preprocessing the image
  IMG = process_image(thresh)

  Images.append(IMG)

Images = np.asarray(Images)

"""## Loading the OCR Model"""

from sklearn.externals import joblib

ocr_model = joblib.load('/content/OCR_Model (1).pkl')

ocr_model

# Predict the Labels using the reloaded Model
predict = ocr_model.predict(Images) 

import keras.backend as K

# use CTC decoder
test_decoded = K.ctc_decode(predict,   
                       input_length=np.ones(predict.shape[0]) * predict.shape[1],
                       greedy=True)[0][0]

Test_out = K.get_value(test_decoded)

# see the results
for i, x in enumerate(Test_out):
  #print("original text = ", list[i])
  print("predicted text = ", end = '')
  for p in x:
      if int(p) != -1:
          print(char_list[int(p)], end = '')
  plt.imshow(Images[i].reshape(32,128), cmap = 'gray')
  plt.show()
  print('\n')

Text = []
for i, x in enumerate(Test_out):
  s = ''
  for p in x:
    if int(p) != -1:
      s = s + char_list[int(p)]
  Text.append(s)

pip install pyspellchecker

"""## Using SpellChecker"""

from spellchecker import SpellChecker

spell = SpellChecker()

Corrected = ''
for word in Text:

  print(spell.correction(word))
  Corrected += ' ' + spell.correction(word)

"""## Saving to csv"""

with open('OCR_res.csv', 'w') as f:
    for word in Corrected:
        f.write(word)

